{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "stop_words = stopwords.words('english')\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(line):\n",
    "    s=re.sub(r'<.+?>', '', line)\n",
    "    s =re.sub(\"\\d+\", \"\", s)\n",
    "    s=s.replace('@en .', '')\n",
    "    s= re.sub(r'[\\(\\)\\\"\\:\\.\\$\\&\\'\\#\\%\\[\\]\\+\\!\\?\\-\\\\]','',s)\n",
    "    s=s.replace('\\n','')\n",
    "    s=s.replace(';','')\n",
    "    s=re.sub(r\"\\b[a-zA-Z]\\b\", \"\", s)\n",
    "    s=s.replace('u\\2014',' ')\n",
    "    s=re.sub(r'\\([^)]*\\)', '', s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "f=open('/home/kapil/Documents/IISc_sem/Machine_Learning_Large_Datasets/Assignment2/DBPedia.full/full_train.txt','r')\n",
    "lines=f.readlines()\n",
    "Words=[]\n",
    "for line in lines:\n",
    "    List1=[]\n",
    "    line=text_processing(line)\n",
    "    line=line.lower()\n",
    "    for word in line.split('\\t')[1].split():  \n",
    "        word=re.sub(r\"[^a-zA-Z]\",\"\",word)\n",
    "        if word not in stop_words:\n",
    "            List1.append(word.rstrip())\n",
    "    Words.append(List1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Titles=set()\n",
    "total_ex=0\n",
    "for line in lines:\n",
    "    line=line.lower()\n",
    "    line=text_processing(line)\n",
    "    for title in line.split('\\t')[0].split(','):\n",
    "        Titles.add(title.rstrip())\n",
    "        total_ex+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298176\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(total_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dict(enumerate(Titles))\n",
    "inv_map = {v: k for k, v in b.items()}\n",
    "target=np.zeros((total_ex, 50))\n",
    "counter=0\n",
    "for line in lines:\n",
    "    line=text_processing(line).lower()\n",
    "    for title in line.split('\\t')[0].split(','):\n",
    "        target[counter,inv_map[title.rstrip()]]=1\n",
    "        counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Softmax(W,emb,n,k,Y):\n",
    "    sum1=0\n",
    "    for k1 in range(50):\n",
    "        sum1+=np.exp(np.dot(W[:,k1],emb))\n",
    "    Y[n,k]=np.exp(np.dot(W[:,k],emb))/sum1\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "298176\n"
     ]
    }
   ],
   "source": [
    "W=np.random.randn(100, 50)\n",
    "print(W[:,1].shape)\n",
    "print(total_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kapil/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      " 10% |#######                                                                 |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2466.254831790924 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20% |##############                                                          |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4865.425188779831 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30% |#####################                                                   |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 7265.362658023834 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40% |############################                                            |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 9695.706987380981 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50% |####################################                                    |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 12101.836040973663 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60% |###########################################                             |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 14598.24015045166 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70% |##################################################                      |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 17335.245698451996 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80% |#########################################################               |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 19735.880929231644 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% |################################################################        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 22177.845766067505 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 24829.04036974907 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "W=np.random.randn(100, 50)\n",
    "Y=np.zeros((total_ex,50))\n",
    "f=open('/home/kapil/Documents/IISc_sem/Machine_Learning_Large_Datasets/Assignment2/DBPedia.full/full_train.txt','r')\n",
    "lines=f.readlines()\n",
    "mue=0.0001\n",
    "lmda=0.1\n",
    "\n",
    "num_epoch=10\n",
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "start_time = time.time()\n",
    "for epoch in pbar(range(num_epoch)):\n",
    "    n=0\n",
    "    for line in lines:\n",
    "        Doc_rep=0\n",
    "        count=0\n",
    "        try:  \n",
    "            line=text_processing(line).lower()\n",
    "            for word in line.split('\\t')[1].split():\n",
    "                word=re.sub(r\"[^a-zA-Z]\",\"\",word)\n",
    "                if word not in stop_words:\n",
    "                    try:\n",
    "                        Doc_rep+=model[word.rstrip()]\n",
    "                    except KeyError:\n",
    "                        continue\n",
    "                count+=1\n",
    "            emb=Doc_rep/count\n",
    "            for title in line.split('\\t')[0].split(','):\n",
    "                for i in range(50):\n",
    "                    Y=Softmax(W,emb,n,i,Y)\n",
    "                    W[:,i]=W[:,i]*(1-mue*lmda)-mue*(Y[n,i]-target[n,i])*emb \n",
    "                n+=1\n",
    "        \n",
    "        except ZeroDivisionError:\n",
    "            continue\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1=np.zeros((total_ex,50))\n",
    "def Softmax1(W,emb,n,k,Y1):\n",
    "    sum1=0\n",
    "    for k1 in range(50):\n",
    "        sum1+=np.exp(np.dot(W[:,k1],emb))\n",
    "    Y1[n,k]=np.exp(np.dot(W[:,k],emb))/sum1\n",
    "    return Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kapil/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "f=open('/home/kapil/Documents/IISc_sem/Machine_Learning_Large_Datasets/Assignment2/DBPedia.full/full_test.txt','r')\n",
    "lines=f.readlines()\n",
    "n1=0\n",
    "num_ex=0\n",
    "correct=0\n",
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "for line in pbar(lines):\n",
    "    num_ex+=1\n",
    "    T1=[]\n",
    "    line=text_processing(line).lower()\n",
    "    Doc_rep1=np.zeros((100,))\n",
    "    emb1=0\n",
    "    count1=0\n",
    "    try:\n",
    "        for word in line.split('\\t')[1].split():\n",
    "            word=re.sub(r\"[^a-zA-Z]\",\"\",word)\n",
    "            if word not in stop_words:\n",
    "                try:\n",
    "                    Doc_rep1+=model[word.rstrip()]\n",
    "                except KeyError:\n",
    "                    continue\n",
    "            count1+=1\n",
    "        if Doc_rep1.all()==0:\n",
    "            continue\n",
    "        emb1=Doc_rep1/count1\n",
    "        for t in line.split('\\t')[0].split(','):\n",
    "            T1.append(t.rstrip())\n",
    "        for i in range(50):\n",
    "            Y1=Softmax1(W,emb1,n1,i,Y1)      \n",
    "        if b[list(Y1[n1,:]).index(max(list(Y1[n1,:])))] in T1:\n",
    "            correct+=1\n",
    "        n1+=1\n",
    "    except ZeroDivisionError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2143690615102517\n"
     ]
    }
   ],
   "source": [
    "print(correct/n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indian_films \t  shanthi nivasa kannada ucbucbeucucaucbf ucaucbfucbucbeucb is   indian kannada film, directed by   bhargava and produced by   manik chand and   mohan the film stars anant nag, bharathi, vijayakashi and ramesh bhat in lead roles the film had musical score by  ranga rao\n",
      "(100,)\n",
      "[ 0.20119135 -0.23242852 -0.37620047  0.6432703   0.3805988  -0.14872755\n",
      " -0.02106177  0.220505    0.60288537 -0.8069491  -0.17061305 -0.51156706\n",
      "  0.40369982 -0.6273393   0.79997253 -0.22948486 -0.5748347   0.88297635\n",
      "  0.27585208  0.22398368  0.73144627  0.2317198  -0.23646776  0.33703753\n",
      "  0.13311142  0.5658218   0.2748705  -0.3614643   0.42045656  0.5399151\n",
      "  0.33698383 -0.06387739  0.45785668 -0.60800755 -0.31503665  0.50295\n",
      "  0.360392   -0.13579127 -0.0717108  -0.3803081   0.9296617  -0.09707762\n",
      " -0.152438    0.4720538  -1.1060071   0.06770971  0.32260674  0.3079747\n",
      " -0.8669964  -0.5402027  -0.66552854  0.5199623   0.30389026  0.5060264\n",
      "  0.13928896  0.29287788  0.58820206 -0.6667451  -0.9466933   0.04397874\n",
      " -0.15054978 -0.49193874 -0.4738467  -0.05684767 -0.5516588   0.21351492\n",
      "  0.34420264 -0.87432045 -0.8819674  -0.24132091  0.589256   -0.17512184\n",
      " -0.31544662 -0.01302743  0.772074   -0.3137308  -0.07500259 -0.13103493\n",
      " -0.13290246  0.46725595  0.21356241 -0.59377986 -0.12373579 -0.25161573\n",
      " -0.106221    0.10139307 -0.54847586  0.15629585 -0.26202026 -0.6179707\n",
      "  0.51647717 -0.3656329   0.14523016 -0.6716901   0.42850277  0.768183\n",
      "  0.32691205  0.60214543 -0.51267636  0.39927596]\n",
      "[-2.3340921  -0.7550279  -2.4559965   2.3698008   3.9111304   2.5853102\n",
      "  1.2213933  -0.13613741  1.6920685  -1.0020673  -0.00824526 -1.1864067\n",
      " -1.0541068  -2.421881    0.20276028  2.8438258  -6.627351    5.456597\n",
      "  0.853371   -3.159694    1.9650068   3.2744522  -0.19720718 -2.502376\n",
      "  1.3641965   3.053561   -2.083303   -4.2418137   0.6282149  -1.288082\n",
      " -0.69016796  0.12757461  3.8534362   0.32780343 -2.16436     1.3903946\n",
      "  2.8568058  -2.4953985  -3.4301896  -3.2181697   3.863593   -2.7853227\n",
      " -0.23326424 -0.21319208 -4.8264265  -2.1244183   2.0236294   2.3042738\n",
      " -3.4571137   1.9372079   3.2464132   1.1900885   0.5991793  -1.0270348\n",
      "  1.2347167  -1.0852897   1.1419955  -4.538086   -5.190445   -1.165207\n",
      " -3.2551177  -3.9754336   0.20720214  1.8470789  -0.9681705  -2.0188608\n",
      " -0.91126966  1.2223674  -0.8596942  -2.3179343  -1.0221896  -0.14402021\n",
      "  0.6456507   1.8442858   3.6883955  -0.9629022   3.3279188  -2.9264739\n",
      "  0.6763454  -0.44603983  2.8039718  -3.050484    0.43768588 -1.2739148\n",
      " -2.8807561  -0.09575119  1.3388413   1.0995623  -0.00697053 -5.473814\n",
      " -0.6521351  -2.5118532   1.0527768  -5.4320564   1.9672034   2.5984433\n",
      "  4.059432    0.8468671  -2.909025    2.272591  ]\n",
      "[ 5.81664301e-03 -1.04332540e-02 -2.42659376e-03 -1.53090035e-02\n",
      " -1.17806659e-02 -3.55297011e-03 -2.23970940e-02  1.46823344e-02\n",
      " -3.60040773e-03  1.48072179e-02  1.02366077e-04  1.33933929e-02\n",
      "  2.78892650e-03  6.84184414e-03  7.19001007e-03 -5.95491640e-03\n",
      "  1.14168178e-02 -1.60076632e-02  9.14842481e-03 -2.56426481e-03\n",
      " -7.83139515e-03  1.08786511e-02  2.40345859e-02 -4.94206105e-03\n",
      "  4.95563040e-03 -8.32946980e-03  1.46312700e-02  4.14666807e-03\n",
      " -1.89551903e-02  1.10595203e-02 -8.62346475e-03  4.79617805e-04\n",
      "  2.48942952e-03 -9.94528039e-03 -6.68552618e-03  5.82889600e-03\n",
      "  4.74142430e-03 -7.70629878e-04  6.93912488e-03  1.36687562e-02\n",
      "  1.99851966e-04  1.12323360e-02 -2.55359610e-03  1.15874586e-02\n",
      "  2.58470066e-03 -1.51468125e-02 -8.21566767e-03 -6.66892917e-05\n",
      " -4.99177995e-03  2.99369707e-02  9.05363199e-03 -7.07105595e-03\n",
      " -8.44670303e-03  1.26822262e-03  1.27810600e-02  9.01600563e-03\n",
      " -8.74610731e-03  1.21398716e-02  1.17677204e-02 -1.29388148e-04\n",
      " -8.03255097e-03 -1.12266993e-03 -9.04476714e-03 -3.39189554e-03\n",
      "  1.85394117e-02  2.39675844e-03 -4.72910755e-03 -1.61924299e-02\n",
      "  2.08449222e-02  7.72467351e-03 -6.12908096e-03  3.54442012e-03\n",
      " -5.82290650e-03  5.34787918e-03  4.98572474e-03  6.04846763e-03\n",
      "  5.10439454e-03  4.01944039e-03  4.16206784e-03 -4.30406865e-03\n",
      "  7.92204592e-04 -2.45258135e-03  1.13487394e-02 -6.04054665e-03\n",
      " -1.39901468e-02  1.29574749e-03  2.32945749e-02 -1.99478711e-02\n",
      "  1.57079152e-02 -2.96199666e-03 -4.42265521e-03  2.73515401e-02\n",
      " -1.24276632e-02 -1.12015888e-03 -3.49349904e-03  5.83301597e-03\n",
      "  1.37215331e-02  1.24520356e-02 -5.59613052e-03  4.72996368e-03]\n",
      "0.016100146252270235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kapil/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  del sys.path[0]\n",
      "/home/kapil/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "#print(correct/n1)\n",
    "#print(num_ex)\n",
    "#print(lines[num_ex])\n",
    "print(text_processing(lines[num_ex-1]).lower())\n",
    "#Y1=Softmax1(W,emb1,n1,i,Y1)\n",
    "emb2=0\n",
    "count2=0\n",
    "Doc_rep2=0\n",
    "for word in text_processing(lines[num_ex-1]).lower().split('\\t')[1].split():\n",
    "    word=re.sub(r\"[^a-zA-Z]\",\"\",word)\n",
    "    if word not in stop_words:\n",
    "        try:\n",
    "            Doc_rep2+=model[word.rstrip()]\n",
    "        except KeyError:\n",
    "            continue\n",
    "    count2+=1\n",
    "emb2=Doc_rep2/count2\n",
    "print(Doc_rep2.shape)\n",
    "print(emb2)\n",
    "print(model['directed'])\n",
    "sum2=0\n",
    "for k2 in range(50):\n",
    "    sum2+=np.exp(np.dot(W[:,k2],emb2))\n",
    "print(W[:,i])\n",
    "print(np.exp(np.dot(W[:,i],emb2))/sum2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
